{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import svm\n",
    "import sklearn.preprocessing as skp\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.metrics as sx\n",
    "from scipy.spatial.distance import euclidean\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"svm-data.csv\", header=None)\n",
    "df = df.set_index(pd.RangeIndex(start=1, stop=len(df)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df.loc[:,df.columns[0]]\n",
    "X = df.loc[:,df.columns[1:]]\n",
    "Xs = skp.StandardScaler().fit_transform(X)\n",
    "\n",
    "cl = svm.SVC(C=10000000, random_state=241, kernel='linear').fit(Xs, y)\n",
    "s1 = \",\".join([str(s) for s in sorted([i for i in df.index[cl.support_]])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w2_0.txt', mode='w') as f: \n",
    "    f.write(s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "newsgroups = datasets.fetch_20newsgroups(subset='all', categories=['alt.atheism', 'sci.space'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectoriser = TfidfVectorizer(stop).fit(newsgroups.data)\n",
    "X = vectoriser.transform(newsgroups.data)\n",
    "y = newsgroups.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = {'C': np.power(10.0, np.arange(-5, 6))}\n",
    "cv = ms.KFold(n_splits=5, shuffle=True, random_state=241)\n",
    "clf = svm.SVC(kernel='linear')\n",
    "gs = ms.GridSearchCV(clf, grid, scoring='accuracy', cv=cv, n_jobs=1)\n",
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear', random_state=241, C=10).fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [(i, w) for i, w in enumerate(np.ravel(clf.coef_.toarray()))]\n",
    "l_sorted = sorted(l, key=lambda x: abs(x[1]), reverse=True)\n",
    "result = np.array(vectoriser.get_feature_names())[[i for i, x in l_sorted[0:10]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = \",\".join([str(r) for r in sorted(result)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('w2_1.txt', mode='w') as f: \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data-logistic.csv\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = (df.loc[:, df.columns[0]] > 0).astype(int) # converting -1,1  to 0,1\n",
    "#y = df.loc[:, df.columns[0]].values\n",
    "X = df.loc[:, df.columns[1:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad1(w, k, C):\n",
    "    return k*np.mean(y*X[:,0]*(1 - np.power(1 + np.exp(-y*(w[0]*X[:,0] + w[1]*X[:,1])), -1))) - k*C*w[0]\n",
    "\n",
    "def grad2(w, k, C):\n",
    "    return k*np.mean(y*X[:,1]*(1 - np.power(1 + np.exp(-y*(w[0]*X[:,0] + w[1]*X[:,1])), -1))) - k*C*w[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 10000\n",
    "w0 = np.array([0,0])\n",
    "i = 0\n",
    "eps = 1\n",
    "w = np.array(w0)\n",
    "C= 0.\n",
    "k = 0.1\n",
    "while (i <= max_iter) and (eps >=1e-5):\n",
    "    z = np.array([w[0] + grad1(w, k=k, C=C),  w[1] + grad2(w, k=k, C=C)])\n",
    "    eps = euclidean(z, w)\n",
    "    w = z\n",
    "    i += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def expit(x, w):\n",
    "    return np.power(1 + np.exp(-np.dot(x, w)), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = np.apply_along_axis(lambda z: expit(z, w), 1, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = sx.roc_auc_score(y, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w3_41.txt\", mode='w') as f:\n",
    "    f.write(\"%.3f\" % result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = pd.read_csv(\"scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = pd.read_csv(\"classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = sx.confusion_matrix(classification['true'], classification['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TN = CM[0,0]\n",
    "TP = CM[1,1]\n",
    "FP = CM[0,1]\n",
    "FN = CM[1,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w4_1.txt\", mode='w') as f:\n",
    "    f.write(\"%d %d %d %d\" % (TP, FP, FN, TN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = sx.accuracy_score(classification['true'], classification['pred'])\n",
    "prec = sx.precision_score(classification['true'], classification['pred'])\n",
    "recall = sx.recall_score(classification['true'], classification['pred'])\n",
    "f1 = sx.f1_score(classification['true'], classification['pred'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w4_2.txt\", mode='w') as f:\n",
    "    f.write(\"%.2f %.2f %.2f %.2f\" % (acc, prec, recall, f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_rauc(col):\n",
    "    return sx.roc_auc_score(scores['true'], scores[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scores_pr(col):\n",
    "    prec, recall, th  = sx.precision_recall_curve(scores['true'], scores[col] )\n",
    "    return np.max(prec[recall > 0.7]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raucs = [(c,scores_rauc(c)) for c in scores.columns if c != 'true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs  = [(c,scores_pr(c)) for c in scores.columns if c != 'true']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(raucs, key=lambda x: x[1])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w4_3.txt\", mode='w') as f:\n",
    "    f.write(\"%s\" % (max(raucs, key=lambda x: x[1])[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"w4_4.txt\", mode='w') as f:\n",
    "    f.write(\"%s\" % (max(prs, key=lambda x: x[1])[0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
