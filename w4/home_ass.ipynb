{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge Reg Linear assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "import  scipy.sparse as ss\n",
    "import sklearn.preprocessing as skp\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv(\"./salary-train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test = pd.read_csv(\"./salary-test-mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def text_preprocess(t: str) -> str:\n",
    "    z = t.lower()\n",
    "    z = re.sub('[^a-zA-Z0-9]', ' ', z)\n",
    "    return z\n",
    "\n",
    "df_train = data_train.assign(FullDescription = data_train['FullDescription'].apply(text_preprocess))\\\n",
    "           .fillna({'LocationNormalized': 'nan', 'ContractTime': 'nan'})\n",
    "\n",
    "df_test = data_test.assign(FullDescription = data_test['FullDescription'].apply(text_preprocess))\\\n",
    "          .fillna({'LocationNormalized': 'nan', 'ContractTime': 'nan'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(min_df=5, max_df = 1e10).fit(df_train['FullDescription'])\n",
    "\n",
    "X_tr_1 = tfidf.transform(df_train['FullDescription'])\n",
    "X_te_1 = tfidf.transform(df_test['FullDescription'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = DictVectorizer().fit(df_train[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "\n",
    "X_tr_2 = oh.transform(df_train[['LocationNormalized', 'ContractTime']].to_dict('records'))\n",
    "X_te_2 = oh.transform(df_test[['LocationNormalized', 'ContractTime']].to_dict('records'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr = ss.hstack([X_tr_1,X_tr_2 ])\n",
    "X_te = ss.hstack([X_te_1, X_te_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = df_train['SalaryNormalized']\n",
    "y_te = df_test['SalaryNormalized']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.linear_model as sklm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl = sklm.Ridge(alpha = 1, random_state=241)\n",
    "cl.fit(X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"t1.txt\", \"w\") as fh:\n",
    "    s = \" \".join([\"%.2f\" % z for z in list(cl.predict(X_te))])\n",
    "    fh.write(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PCA Assignment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"close_prices.csv\")\n",
    "dj = pd.read_csv(\"djia_index.csv\")\n",
    "dj = dj.set_index(pd.DatetimeIndex(dj.date)).drop(columns=['date'])\n",
    "X = df.set_index(pd.DatetimeIndex(df.date)).drop(columns=['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpca = PCA(n_components=10).fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = range(1, len(X.columns) + 1)\n",
    "d  = [PCA(n_components=k).fit(X).explained_variance_ratio_.cumsum()[-1] for k in n]\n",
    "d1 = [PCA(n_components=k).fit(skp.StandardScaler().fit_transform(X)).explained_variance_ratio_.cumsum()[-1] for k in n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(n, d, label='no std')\n",
    "plt.plot(n, d1, label='std')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
